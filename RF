#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Fri Jun 12 16:50:31 2020

@author: vinoothna
"""

import numpy  as np # Import numpy
import matplotlib.pyplot as plt #import matplotlib library

from matplotlib import interactive
interactive(True)
import numpy as np
import matplotlib.pyplot as plt
import scipy as sc
from scipy import stats 
import sklearn
from sklearn.preprocessing import normalize
from scipy import signal
from scipy import stats
from numpy import linalg as LA
from scipy.signal import find_peaks
from scipy.signal import butter, lfilter
from scipy.interpolate import CubicSpline
from scipy.fftpack import fft, ifft
import scipy as sc      
from scipy import stats 
from scipy.fftpack import fft
from scipy.signal import spectrogram as sp
from sklearn.linear_model import LogisticRegression
from sklearn import metrics
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
#from sklearn.metrics import plot_confusion_matrix
fname ="/Users/vinoothna/Desktop/Quarter 3/PredictiveAnalytics/MODULE3/HW3data/train_set.csv"
#all_data = [line.rstrip('[').rstrip(']') for line in open(fname)];
all_data=[[float(num) for num in line.rstrip('\n').replace('[',' ').replace(']',' ').replace(',',' ').split()] for line in open(fname)];

fname1 ="/Users/vinoothna/Desktop/Quarter 3/PredictiveAnalytics/MODULE3/HW3data/test_set.csv"
##all_data = [line.rstrip('[').rstrip(']') for line in open(fname)];
all_data1=[[float(num) for num in line.rstrip('\n').replace('[',' ').replace(']',' ').replace(',',' ').split()] for line in open(fname1)];
#
all_data1= np.asarray(all_data1) 
train=np.empty((50,))
test=np.empty((50,))
#
train_y=np.empty((5,))
test_y=np.empty((5,))
u=0
for i in range(5000):
    
       
    x = all_data[i][0:50]
    #new_im.show()
    x=np.asarray(x)
    y= all_data[i][50:55]
    y=np.asarray(y)
    
    
#    x=(x-np.min(x))/(np.max(x)-np.min(x))
    train_y=np.vstack((train_y,y))
    train = np.vstack((train, x))










    
train=train[1:][:] 
train_y=train_y[1:][:] 
for i in range(1000):
    
       
    x = all_data1[i][0:50]
    #new_im.show()
    x=np.asarray(x)
    y= all_data1[i][50:55]
    y=np.asarray(y)
    
    
#    x=(x-np.min(x))/(np.max(x)-np.min(x))
    test_y=np.vstack((test_y,y))
    test = np.vstack((test, x))    
    
    
test=test[1:][:] 
test_y=test_y[1:][:] 
 
#
#
#
#
#


# random forest for multioutput regression
from sklearn.datasets import make_regression
from sklearn.ensemble import RandomForestRegressor
# create datasets
train, train_y = make_regression(n_samples=5000, n_features=50, n_informative=50, n_targets=5, random_state=1)
# define model
model = RandomForestRegressor(n_estimators=1000)
# fit model
model.fit(train, train_y)


predictions = model.predict(test)
#
#Use score method to get accuracy of model
print(np.sqrt(metrics.mean_squared_error(test_y,predictions)))
#
#lr_probs = logisticRegr.predict_proba(x_test)
## keep probabilities for the positive outcome only
#lr_probs = lr_probs[:, 1]
## calculate scores
#
#lr_auc = roc_auc_score(y_test, lr_probs)
## summarize scores
#
#print('Logistic: ROC AUC=%.3f' % (lr_auc))
## calculate roc curves
#
#lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs,pos_label=1)
## plot the roc curve for the model
#
#plt.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')
## axis labels
#plt.xlabel('False Positive Rate')
#plt.ylabel('True Positive Rate')
## show the legend
#plt.legend()
## show the plot
#plt.show()
## Plot non-normalized confusion matrix
#titles_options = [("Confusion matrix, without normalization", None),
#                  ("Normalized confusion matrix", 'true')]
#
#
#plt.show()
#plot_confusion_matrix(logisticRegr, x_test, y_test) 
#plt.show() 
##
##from sklearn.metrics import precision_recall_curve
##from sklearn.metrics import plot_precision_recall_curve
##import matplotlib.pyplot as plt
##
##disp = plot_precision_recall_curve(logisticRegr, x_test, y_test)
##disp.ax_.set_title('2-class Precision-Recall curve: '
##                   )
#from sklearn.metrics import precision_recall_curve
#precision, recall, thresholds = precision_recall_curve(y_test, lr_probs,pos_label=1) 
#   #retrieve probability of being 1(in second column of probs_y)
#pr_auc = metrics.auc(recall, precision)
#
#plt.title("Precision-Recall vs Threshold Chart")
#plt.plot(thresholds, precision[: -1], "b--", label="Precision")
#plt.plot(thresholds, recall[: -1], "r--", label="Recall")
#plt.ylabel("Precision, Recall")
#plt.xlabel("Threshold")
#plt.legend(loc="lower left")
#plt.ylim([0,1])